## Graphs

Two representations: adjacency matrix and adjacency list

- Adj matrix is very simple to use: each entry i,j represents a connection i->j, w/ the entry being the # connections
  - For undirected graphs, the matrix is symmetric, so lots of space is wasted
  - Downside: storage is expensive, O(V^2), and most graphs are sparse (relatively few edges compared to vertices)

- Adj list is also pretty simple: take a list, where each entry at v is a list of edges connected to v.
  - To check a connection between v and w, query w in adj[v]
  - Note: for both cases, undirected graphs require you to update connections for both v and w.
  - To print a graph, simply iterate through each vertex and their connections - O(V+E) (O(V) if sparse, O(V^2) if dense)
  


## DFS algorithm 
The idea is to go deep before wide. Some tree traversals (pre/post/in) are examples of DFS-esque algorithms:
you visit leaves first. 

This is a recursive implementation, using a visited dict to mark whether a vertex has been visited.

visited = dict.fromkeys(vertices, 0) # maps all vertices to 0

def DFS(G, v):
    visited[v] = 1
    for w in G.adj(v):
        if not visited[w]:
            DFS(G, w)
            
Potential problems: stack overflow for deep graphs. Since DFS visits each vertex exactly once via edges, 
runtime is O(V+E). Since we store the visited property in a list and accounting for the recursive stack, we use O(V) space.
            
For an iterative solution, simply use a stack instead:

def DFS(G, v):
    stack = [v]
    while len(stack) > 0:
        v = stack.pop()
        visited[v] = 1
        for w in G.adj(v): 
            if not visited[w]: 
                stack.append(w)
                
Here we're not limited by recursion depth, and we use an explicit stack. 

#Important note#: the order of the recursive/iterative algorithms may not be the same (namely the order in which
children are visited). This is because a recursive approach will visit children in an order (A,B,C), while the iterative
approach will visit children in the reverse order (C,B,A), since we're pushing to the stack in order (A,B,C).


## BFS algorithm
BFS uses the opposite approach: go wide before deep. It's akin to a level-order traversal of a tree.

def BFS(G, v):
    queue = [v]
    while len(queue) > 0:
        v = queue.remove(0) # we remove from the front of the queue, and append to the end
        visited[v] = 1 
        for w in G.adj(v):
            if not visited[w]: 
                queue.append(w)
                
The implementation is basically an iterative DFS but using a queue. This allows us to visit levels one at a time.
Again, runtime is O(V+E), since we visit each node exactly once. 
        
